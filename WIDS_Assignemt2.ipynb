{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce222ca-c042-4e98-8c0a-e01beba8c692",
   "metadata": {},
   "source": [
    "### WIDS ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022988a-c326-4de0-af22-2bb47a30ff89",
   "metadata": {},
   "source": [
    "##### QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3de4e56-2a8c-4c5f-bda8-cb5e978ae7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb98a12-9bb0-45e8-8949-8323e1cb8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_match(pattern, text):\n",
    "    matches = re.findall(pattern, text)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else :\n",
    "        return \"there is no phone number in it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906e360a-0ef3-492f-81cd-807cb414eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat1 = 'codebasics: you ask lot of questions ðŸ˜   1235678912, abc@xyz.com'\n",
    "chat2 = 'codebasics: here it is: (123)-567-8912, abc@xyz.com'\n",
    "chat3 = 'codebasics: yes, phone: 1235678912 email: abc@xyz.com'\n",
    "chat4 = \"hello my id is 23B2189\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da3b056-6ea4-45a3-9c19-a5ac3337f533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1235678912', '')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '(\\d{10})|(\\(\\d{3}\\)-\\d{3}-\\d{4})'\n",
    "get_pattern_match(pattern,chat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66669a3d-6087-4383-a9ff-ae60e6281ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '(123)-567-8912')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pattern_match(pattern, chat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8cb94df-0541-40c4-a9c1-eab64a80ee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1235678912', '')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pattern_match(pattern, chat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6895f8d6-dc35-42b0-b073-32a07656851d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there is no phone number in it'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pattern_match(pattern, chat4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645aad9-f976-4306-a35b-9161c8adc301",
   "metadata": {},
   "source": [
    "##### QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8846d98-aa83-4389-b96a-74df5fc46424",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d21ca1e-78b9-4a33-90d0-5a3d1b3265b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: SpaCy, Is Space: False\n",
      "Token: is, Is Space: False\n",
      "Token: a, Is Space: False\n",
      "Token: powerful, Is Space: False\n",
      "Token: NLP, Is Space: False\n",
      "Token: library, Is Space: False\n",
      "Token: for, Is Space: False\n",
      "Token: tokenization, Is Space: False\n",
      "Token: ., Is Space: False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")  \n",
    "text = \"SpaCy is a powerful NLP library for tokenization.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, Is Space: {token.is_space}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd2684-9463-4323-8c10-95667f384b12",
   "metadata": {},
   "source": [
    "##### QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d9e10e8-6c82-4b97-9258-90837466881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from spacy.language import Language\n",
    "\n",
    "\n",
    "@Language.component(\"token_count_component\")\n",
    "def token_count_component(doc):\n",
    "    print(f\"Number of tokens: {len(doc)}\")\n",
    "    return doc\n",
    "\n",
    "nlp1= spacy.blank(\"en\")\n",
    "nlp1.add_pipe(\"token_count_component\", last=True)\n",
    "text = \"Customizing a SpaCy pipeline can be very useful.\"\n",
    "doc = nlp1(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377524d1-2e4e-4fa1-84fa-8b43a4141dc0",
   "metadata": {},
   "source": [
    "\n",
    "##### QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d14910da-9be9-4d76-9d30-f847d5825f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: NLP, POS: PROPN, Dependency: nsubj\n",
      "Word: is, POS: AUX, Dependency: ROOT\n",
      "Word: fascinating, POS: ADJ, Dependency: acomp\n",
      "Word: ,, POS: PUNCT, Dependency: punct\n",
      "Word: and, POS: CCONJ, Dependency: cc\n",
      "Word: SpaCy, POS: PROPN, Dependency: nsubj\n",
      "Word: makes, POS: VERB, Dependency: conj\n",
      "Word: it, POS: PRON, Dependency: nsubj\n",
      "Word: even, POS: ADV, Dependency: advmod\n",
      "Word: more, POS: ADV, Dependency: advmod\n",
      "Word: interesting, POS: ADJ, Dependency: ccomp\n",
      "Word: ., POS: PUNCT, Dependency: punct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nlp2 = spacy.load(\"en_core_web_sm\")\n",
    "text = \"NLP is fascinating, and SpaCy makes it even more interesting.\"\n",
    "doc = nlp2(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"Word: {token.text}, POS: {token.pos_}, Dependency: {token.dep_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93768aab-8c55-45ea-9cd2-5178c0cfec67",
   "metadata": {},
   "source": [
    "##### QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5eb777ee-9970-48a9-af6e-41869163c0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Elon Musk, Label: PERSON, Description: People, including fictional\n",
      "Entity: Tesla, Label: ORG, Description: Companies, agencies, institutions, etc.\n",
      "Entity: June 28, 1971, Label: DATE, Description: Absolute or relative dates or periods\n",
      "Entity: Pretoria, Label: GPE, Description: Countries, cities, states\n",
      "Entity: South Africa, Label: GPE, Description: Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Elon Musk, the CEO of Tesla, was born on June 28, 1971, in Pretoria, South Africa.\"\n",
    "doc = nlp2(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}, Description: {spacy.explain(ent.label_)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80a5c1-b3ae-4225-84c9-cff55c681ab8",
   "metadata": {},
   "source": [
    "##### QUESTION 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a14745-8c7b-486d-b387-94c255dbccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hot Encoding:\n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "Bag of Words:\n",
      " [[1 1 1 0 0 0 0 1]\n",
      " [0 1 1 1 1 1 1 1]]\n",
      "TF-IDF:\n",
      " [[0.63009934 0.44832087 0.44832087 0.         0.         0.\n",
      "  0.         0.44832087]\n",
      " [0.         0.30287281 0.30287281 0.42567716 0.42567716 0.42567716\n",
      "  0.42567716 0.30287281]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text_corpus = [\"Data science is amazing\", \"Machine learning is part of data science\"]\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "one_hot_encoded = one_hot.fit_transform([[sentence] for sentence in text_corpus]).toarray()\n",
    "print(\"One Hot Encoding:\\n\", one_hot_encoded)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(text_corpus)\n",
    "print(\"Bag of Words:\\n\", bow.toarray())\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(text_corpus)\n",
    "print(\"TF-IDF:\\n\", tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e513e-00df-4f5c-a741-0ab04a069781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
